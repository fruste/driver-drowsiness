{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blinking detection\n",
    "This notebook processes the provided subject, and detects the face, eyes and identifies the eye state of each frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from imutils import face_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance as dist\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Displayinh the number of GPUs available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_blink(eye_img):\n",
    "    pred_B = model_b.predict(eye_img, verbose=0)\n",
    "    status = pred_B[0][0]\n",
    "    status = status*100\n",
    "    status = round(status,3)\n",
    "    return  status\n",
    "\n",
    "   \n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(int)\n",
    "\n",
    "    eye_img = img[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n",
    "\n",
    "def get_eyes(shape):\n",
    "    (leftEyeStart, leftEyeEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    (rightEyeStart, rightEyeEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "    left_eye = shape[leftEyeStart:leftEyeEnd]\n",
    "    right_eye = shape[rightEyeStart:rightEyeEnd]\n",
    "    \n",
    "    return left_eye, right_eye\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    p2_minus_p6 = dist.euclidean(eye[1], eye[5])\n",
    "    p3_minus_p5 = dist.euclidean(eye[2], eye[4])\n",
    "    p1_minus_p4 = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (p2_minus_p6 + p3_minus_p5) / (2.0 * p1_minus_p4)\n",
    "    return ear\n",
    "\n",
    "# load a test image, resize it, and convert it to grayscale\n",
    "def load_image(path, show=False, gray_show=False):\n",
    "    test_image = cv2.imread(path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    test_image = imutils.resize(test_image, width=500)\n",
    "    gray = cv2.cvtColor(test_image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if show:\n",
    "        plt.imshow(test_image)\n",
    "        plt.show()\n",
    "        if gray_show:\n",
    "            plt.imshow(gray, cmap='gray')\n",
    "            plt.show()\n",
    "    return test_image, gray\n",
    "\n",
    "def detect_faces(face_detector, gray, scale_factor, frame_num, show_multi_faces = False):\n",
    "     # detect faces in the grayscale image\n",
    "    multi_face = 0\n",
    "    if face_detector == 'dlib':\n",
    "        rects = detector(gray, 1)\n",
    "        if len(rects) == 0:\n",
    "            print('No face detected', frame_num)\n",
    "            return False\n",
    "        elif len(rects) > 1:\n",
    "            print('more faces detected')\n",
    "            return False\n",
    "    elif face_detector == 'haar':\n",
    "        detections = haar_cascade.detectMultiScale(gray, scaleFactor=scale_factor, minNeighbors=5, minSize=(150, 150), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        #Checking if there are more than 1 detected faces\n",
    "        if len(detections) > 1:\n",
    "            print('multiple faces', frame_num)\n",
    "            multi_face = 1\n",
    "            # The predicted faces are boxes (same width and height). The last two values correspond to these.\n",
    "            # So by just checking which is higher, I can find the correct face. FOR SUBJECT 16 select the smallest face!\n",
    "            if detections[0][2] > detections[1][2]:\n",
    "                face = detections[1]\n",
    "                other = detections[0]\n",
    "            else:\n",
    "                face = detections[0]\n",
    "                other = detections[1]\n",
    "            if show_multi_faces:\n",
    "                print('chosen face')\n",
    "                fX, fY, fW, fH = face[0],face[1], face[2], face[3]\n",
    "                plt.imshow(gray[fY:fY + fH, fX:fX + fW], cmap='gray')\n",
    "                plt.show()\n",
    "                print('not chosen face')\n",
    "                fX, fY, fW, fH = other[0], other[1], other[2], other[3]\n",
    "                plt.imshow(gray[fY:fY + fH, fX:fX + fW], cmap='gray')\n",
    "                plt.show()\n",
    "        elif len(detections) == 1:\n",
    "            face = detections[0]\n",
    "            # fX, fY, fW, fH = face[0],face[1], face[2], face[3]\n",
    "            # plt.imshow(gray[fY:fY + fH, fX:fX + fW], cmap='gray')\n",
    "            # plt.show()\n",
    "        # if no face detected\n",
    "        elif len(detections) == 0:\n",
    "            print('No face detected', frame_num)\n",
    "            return False, 0\n",
    "        fX, fY, fW, fH = face[0],face[1], face[2], face[3]    \n",
    "        rects = [dlib.rectangle(fX, fY, fX + fW, fY + fH)]\n",
    "    return rects, multi_face\n",
    "\n",
    "def get_landmarks(img, gray, rects, show=False):\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        if show: \n",
    "            # convert dlib's rectangle to a OpenCV-style bounding box [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "            # cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            # loop over the (x, y)-coordinates for the facial landmarks and draw them on the image\n",
    "            for (x, y) in shape:\n",
    "                cv2.circle(img, (x, y), 2, (0, 0, 255), -1)\n",
    "    if show:     \n",
    "        # show the output image with the face detections + facial landmarks\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify subject number and condition.\n",
    "subject = 'P11407'\n",
    "condition = 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_start = 50000\n",
    "frame_end = 50001\n",
    "\n",
    "frames = range(frame_start, frame_end + 1)\n",
    "\n",
    "# Just plotting sequence of frames\n",
    "def plot_frames(frames):\n",
    "    for frame in frames:\n",
    "        path = '../frames/' + subject + '/' + condition + '/frame' + str(frame) + '.jpg'\n",
    "        print(\"Frame: \" + str(frame))\n",
    "        test_img, gray = load_image(path, show=True, gray_show=False)\n",
    "        \n",
    "plot_frames(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (1296,730)\n",
    "B_SIZE = (34, 26)\n",
    "\n",
    "#path = '../test_frames/frame848.jpg'\n",
    "\n",
    "# haar Cascade path\n",
    "cascade_path = '../models/haarcascade_frontalface_default.xml'\n",
    "# create haar cascade\n",
    "haar_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "# define pre-trained landmark detector path\n",
    "ld_path = '../models/shape_predictor_68_face_landmarks.dat'\n",
    "predictor = dlib.shape_predictor(ld_path)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "model_b = load_model('../models/blinkdetection.h5')\n",
    "face_detector = 'haar'\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from numba import cuda \n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_start = 80000#74000\n",
    "frame_end = 81000#210000\n",
    "\n",
    "frames = range(frame_start, frame_end + 1)\n",
    "\n",
    "scale_factor = 1.03\n",
    "\n",
    "folder_path = '../frames/' + subject + '/' + condition + '/frame'\n",
    "\n",
    "# which eye openness calculation method to use: cnn or ear\n",
    "eo_method = 'cnn'\n",
    "\n",
    "def calculate_eye_openness(frames, folder_path, scale_factor, eo_method):\n",
    "    status_rates = []\n",
    "    wrong_frames = []\n",
    "    no_face_count = 0\n",
    "    multi_face_count = 0\n",
    "    for frame in frames:\n",
    "        if frame % 1000 == 0:\n",
    "            print(frame)\n",
    "        if frame % 10000 == 0:\n",
    "            print(\"No Faces: \", no_face_count)\n",
    "            print(\"Multi Faces: \", multi_face_count)\n",
    "        if frame == 100000:\n",
    "            np.save('status_rates_subject25_normal_temp.npy', status_rates)\n",
    "            np.save('wrong_frames_subject25_normal_temp.npy', wrong_frames)\n",
    "        path = folder_path + str(frame) + '.jpg'\n",
    "        test_img, gray = load_image(path, show=False)\n",
    "        rects, multi_face = detect_faces(face_detector, gray, scale_factor, frame, show_multi_faces = False)\n",
    "        \n",
    "        multi_face_count += multi_face\n",
    "        \n",
    "        if rects == False:\n",
    "            no_face_count += 1\n",
    "            # append eye opennes status from previous frame\n",
    "            status_rates.append(status)\n",
    "            wrong_frames.append(frame)\n",
    "            continue\n",
    "            \n",
    "        shapes = get_landmarks(test_img, gray, rects, show=False)\n",
    "        \n",
    "        if eo_method == 'cnn':\n",
    "            eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "            # eye_img_color, _ = crop_eye(test_img, eye_points=shapes[36:42])\n",
    "            eye_blink_left = cv2.resize(eye_img_l.copy(), B_SIZE)\n",
    "            # plt.imshow(eye_img_color)\n",
    "            # plt.show()\n",
    "            eye_blink_left_i = eye_blink_left.reshape((1, B_SIZE[1], B_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "            status = detect_blink(eye_blink_left_i)\n",
    "        \n",
    "        elif eo_method == 'ear':\n",
    "            left_eye, right_eye = get_eyes(shapes)\n",
    "            left_ear = eye_aspect_ratio(left_eye)\n",
    "            right_ear = eye_aspect_ratio(right_eye)\n",
    "            \n",
    "            status = (left_ear + right_ear) / 2\n",
    "        \n",
    "        status_rates.append(status)\n",
    "\n",
    "    print(\"No Faces: \", no_face_count)\n",
    "    print(\"Multiple Faces: \", multi_face_count)\n",
    "    return status_rates, wrong_frames\n",
    "\n",
    "print('Done')\n",
    "status_rates, wrong_frames = calculate_eye_openness(frames, folder_path, scale_factor, eo_method)\n",
    "#np.save('status_rates_subject25_normal.npy', status_rates)\n",
    "#np.save('wrong_frames_subject25_normal.npy', wrong_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Status rate (openness of eyes) of every frame\")\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Rate')\n",
    "plt.plot(frames, status_rates)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the graph more in depth\n",
    "\n",
    "# DONT change these parameters\n",
    "frame_start = 0\n",
    "frame_end = 2774  # normal sleep: last frame is 2804    restricted sleep: last frame is 2774 \n",
    "frames = range(frame_start, frame_end + 1)\n",
    "\n",
    "# CHANGE these parameter\n",
    "frame_start = 110\n",
    "frame_end = 150\n",
    "\n",
    "plt.title(\"Status rate (openness of eyes) of every frame\")\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Rate')\n",
    "plt.plot(frames[frame_start:frame_end], status_rates[frame_start:frame_end])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finds eye-blinks given a sequence of values and a treshhold.\n",
    "def find_blinks(values, treshhold):\n",
    "    blink = False\n",
    "    blinks = []\n",
    "    blink_count = 0\n",
    "    for i, val in enumerate(values):\n",
    "        if val < treshhold:\n",
    "            if blink == False:\n",
    "                blink_count +=1\n",
    "                start = i\n",
    "            blink = True\n",
    "        else:\n",
    "            if blink == True:\n",
    "                end = i - 1\n",
    "                #calculate duration of blink, and include in tuple\n",
    "                duration = end - start + 1\n",
    "                blinks.append((start, end, duration))\n",
    "                #print(\"Blinking period: \" + str(start) + \" - \" + str(end))\n",
    "            blink = False\n",
    "    return blinks, blink_count\n",
    "\n",
    "treshhold = 15\n",
    "blinks, count = find_blinks(status_rates, treshhold)\n",
    "print(blinks)\n",
    "print(np.array(blinks)[:,2])\n",
    "print(len(blinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blink_starts = list(np.array(blinks)[:,0])\n",
    "blink_durs = list(np.array(blinks)[:,2])\n",
    "\n",
    "# Extracts features in a segment from given blinks\n",
    "def blinks_segment(blink_starts, blink_durs, video_len, segment_len):\n",
    "    # the amount of frames at the end that are not taken into account\n",
    "    rest = video_len % segment_len\n",
    "    num_frames = video_len - rest\n",
    "    blink_counts = []\n",
    "    average_durs = []\n",
    "    \n",
    "    blink_count = 0\n",
    "    dur_count = 0\n",
    "    \n",
    "    # a blink is counted to a segment,when the blink starts in that segment\n",
    "    for frame in range(num_frames):\n",
    "        # only happens at the end of a segment\n",
    "        if frame % segment_len == 0 and frame != 0:\n",
    "            #print('new_segment', frame)\n",
    "            blink_counts.append(blink_count)\n",
    "            if dur_count > 0:\n",
    "                avg_dur = dur_count / blink_count\n",
    "            else:\n",
    "                avg_dur = 0\n",
    "            average_durs.append(avg_dur)\n",
    "            blink_count = 0 \n",
    "            dur_count = 0\n",
    "        # happens when a blink starts\n",
    "        if frame in blink_starts:\n",
    "            frame_index = blink_starts.index(frame)\n",
    "            blink_count += 1\n",
    "            dur_count += blink_durs[frame_index]\n",
    "            \n",
    "    return blink_counts, average_durs\n",
    "        \n",
    "    \n",
    "blink_counts, average_durs = blinks_segment(blink_starts, blink_durs, 83000, 2600)\n",
    "\n",
    "# Plotting blink counts\n",
    "plt.title(\"Blink counts of a frame segment\")\n",
    "plt.xlabel('Frame segment')\n",
    "plt.ylabel('Blink counts')\n",
    "plt.plot(range(len(blink_counts)), blink_counts)\n",
    "plt.show()\n",
    "\n",
    "# Plotting average blink durations\n",
    "plt.title(\"Average blink duration of a frame segment\")\n",
    "plt.xlabel('Frame segment')\n",
    "plt.ylabel('Average blink duration')\n",
    "plt.plot(range(len(average_durs)), average_durs)\n",
    "plt.show()\n",
    "\n",
    "print(len(blink_counts))\n",
    "print(len(average_durs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
