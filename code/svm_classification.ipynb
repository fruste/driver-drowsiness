{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Drowsiness Classification\n",
    "The goal of this notebook is to perform classification on my created features using Support Vector Machines. \n",
    "And to experiment with the segment length untill classification cannot be performed correctly anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from helping_functions import *\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(subject, treshhold, segment_length):\n",
    "    status_rates_sleepy, wrong_frames_sleepy = load_blinks(subject, 'sleepy') \n",
    "    #print(\"Sleepy number of frames: \", len(status_rates_sleepy))\n",
    "    #print(\"Sleepy missed faces: \", len(wrong_frames_sleepy))\n",
    "    status_rates_normal, wrong_frames_normal = load_blinks(subject, 'normal') \n",
    "    #print(\"Normal number of frames: \", len(status_rates_normal))\n",
    "    #print(\"Normal missed faces: \", len(wrong_frames_normal))\n",
    "    \n",
    "    print(\"Starting segmenting normal condition\")\n",
    "    blink_counts_normal, average_durs_normal = run_analysis(status_rates_normal, wrong_frames_normal, treshhold, segment_length)\n",
    "\n",
    "    print(\"Starting segmenting sleepy condition\")\n",
    "    blink_counts_sleepy, average_durs_sleepy = run_analysis(status_rates_sleepy, wrong_frames_sleepy, treshhold, segment_length)\n",
    "    \n",
    "    return list(zip(blink_counts_normal, average_durs_normal)), list(zip(blink_counts_sleepy, average_durs_sleepy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(X_normal, X_sleepy):\n",
    "    y_normal = list(np.zeros(len(X_normal)))\n",
    "    y_sleepy = list(np.ones(len(X_sleepy)))\n",
    "\n",
    "    X = X_normal + X_sleepy\n",
    "    y = y_normal + y_sleepy\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_norm = scaler.fit_transform(X)\n",
    "    #print(\"Maximum values :\", scaler.data_max_)\n",
    "    #print(\"Minimum values :\", scaler.data_min_)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3,random_state=41)\n",
    "    \n",
    "    # train model\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1_round =  round(f1, 2) \n",
    "    print(\"F1 score: \", f1_round)\n",
    "\n",
    "\n",
    "    return model, f1_round, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training models for multiple segment lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_seg_lens(subject, treshhold, min_list):\n",
    "    models = []\n",
    "    f1_scores = []\n",
    "    for minutes in min_list:\n",
    "        print(\"Segment length: \" + str(minutes))\n",
    "        segment_length = int(2760 * minutes)\n",
    "        X_normal, X_sleepy = get_data(subject, treshhold, segment_length)\n",
    "        model, f1_round, X_train, X_test, y_train, y_test = train_model(X_normal, X_sleepy)\n",
    "        f1_scores.append(f1_round)\n",
    "        models.append(model)\n",
    "    return models, f1_scores\n",
    "\n",
    "subject = 'subject16'\n",
    "treshhold = 10\n",
    "min_list = [0.2,1,2,5,8]\n",
    "\n",
    "models, f1_scores = multi_seg_lens(subject, treshhold, min_list)\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multi_seg(subject, min_list, f1_scores):\n",
    "    x_values = range(len(min_list))\n",
    "    plt.plot(x_values, f1_scores)\n",
    "    plt.xticks(x_values, min_list)\n",
    "    plt.xlabel('Segment length (in minutes)')\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.title('Classification performance for '+ subject + ' when increasing segment length')\n",
    "    plt.show()\n",
    "    \n",
    "plot_multi_seg(subject, min_list, f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Multiple subjects classification (subject-individually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_subjects(subjects, threshold, min_list):\n",
    "    sum_f1_scores = np.zeros(len(min_list))\n",
    "    all_f1_scores = []\n",
    "    for sub in subjects:\n",
    "        subject = 'subject' + str(sub)\n",
    "        f1_scores = multi_seg_lens(subject, threshold, min_list)[1]\n",
    "        all_f1_scores.append(f1_scores)\n",
    "        sum_f1_scores = sum_f1_scores + np.array(f1_scores)\n",
    "        print(\"SUBJECT\" + str(sub)+ \" DONE\", f1_scores)\n",
    "    avg_f1_scores = sum_f1_scores / len(subjects)\n",
    "\n",
    "    x_values = range(len(min_list))\n",
    "    plt.plot(x_values, list(avg_f1_scores))\n",
    "    plt.xticks(x_values, min_list)\n",
    "    plt.xlabel('Segment length (in minutes)')\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.title('Classification performance for all subjects when increasing segment length')\n",
    "    plt.savefig('../final_figures/class_f1_analysis_poly.jpg')\n",
    "    plt.show()\n",
    "    return all_f1_scores, avg_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = [1,3,4,6,7,9,10,12,14,15,22,23,24]\n",
    "\n",
    "threshold = 10\n",
    "min_list = [0.1,0.5,1,2,5]\n",
    "scores, avg_scores = multi_subjects(subjects, threshold, min_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of too little semgments, subjects 11,16, 20 and 25 are removed\n",
    "trends = {'1':[3,4,6,9,10,14,15,23,24], '2':[1], '3':[7], '4':[12,22]}\n",
    "def plot_performance_trends(scores, avg_scores, trends, min_list):\n",
    "    x_values = range(len(min_list))\n",
    "    \n",
    "    # plotting performance for all trends\n",
    "    plt.plot(x_values, list(avg_scores), label = \"All subjects\", linewidth = 2, color='black')\n",
    "    \n",
    "    # plotting performances across trends individually\n",
    "    for t in range(1,5):\n",
    "        idx = [subjects.index(sub) for sub in trends[str(t)]]\n",
    "        trend_scores = np.array(scores)[idx]\n",
    "        trend_mean = np.mean(trend_scores, axis=0)\n",
    "        plt.plot(x_values, list(trend_mean), label = 'Trend ' + str(t), linewidth=0.7)\n",
    "    \n",
    "\n",
    "    plt.xticks(x_values, min_list)\n",
    "    plt.xlabel('Segment length (in minutes)')\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.legend()\n",
    "    plt.title('Classification performance when increasing segment length')\n",
    "    plt.savefig('../final_figures/class_f1_analysis_trends.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "plot_performance_trends(scores, avg_scores, trends, min_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which subject\n",
    "subject = 'subject1'\n",
    "\n",
    "# Parameters\n",
    "treshhold = 10\n",
    "minutes = 1\n",
    "segment_length = int(2760) * minutes\n",
    "\n",
    "\n",
    "X_normal, X_sleepy = get_data(subject, treshhold, segment_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, f1_round, X_train, X_test, y_train, y_test = train_model(X_normal, X_sleepy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "# Plotting our two-features-space\n",
    "sns.scatterplot(x=X_train[:, 0], \n",
    "                y=X_train[:, 1], \n",
    "                hue=y_train, \n",
    "                s=40);\n",
    "\n",
    "w = model.coef_[0]\n",
    "b = model.intercept_[0]\n",
    "x_points = np.linspace(0, 1)\n",
    "y_points = -(w[0] / w[1]) * x_points - b / w[1]\n",
    "\n",
    "# Plotting a red hyperplane\n",
    "plt.plot(x_points, y_points, c='r');\n",
    "plt.xlabel('Number of blinks (scaled)')\n",
    "plt.ylabel('Blink duration (scaled)')\n",
    "plt.title('SVM classification of ' + subject + ' with segments of ' + str(minutes) + ' min - training phase')\n",
    "#plt.savefig('../figures/svm_' + subject + '_min' + str(minutes) + '-training.jpg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Plotting our two-features-space\n",
    "sns.scatterplot(x=X_test[:, 0], \n",
    "                y=X_test[:, 1], \n",
    "                hue=y_test, \n",
    "                s=40);\n",
    "\n",
    "w = model.coef_[0]\n",
    "b = model.intercept_[0]\n",
    "x_points = np.linspace(0, 1)\n",
    "y_points = -(w[0] / w[1]) * x_points - b / w[1]\n",
    "\n",
    "# Plotting a red hyperplane\n",
    "plt.plot(x_points, y_points, c='r');\n",
    "\n",
    "# Plotting textbox with F1 score\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.1)\n",
    "#plt.text(0.05, 1, \"F1 score : \" + str(f1_round), fontsize=12,\n",
    "        #verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.xlabel('Number of blinks (scaled)')\n",
    "plt.ylabel('Blink duration (scaled)')\n",
    "plt.title('SVM classification of ' + subject + ' with segments of ' + str(minutes) + ' min - test phase')\n",
    "#plt.savefig('../figures/svm_' + subject + '_min' + str(minutes) + '-test.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "model_rbf =  SVC(kernel='rbf')\n",
    "model_rbf.fit(X_train, y_train)\n",
    "plot_decision_regions(X_train, np.array(y_train).astype(np.int_), clf=model_rbf, legend=2)\n",
    "plt.show()\n",
    "\n",
    "y_pred = model_rbf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1_round =  round(f1, 2) \n",
    "print(\"F1 score rbf: \", f1_round)\n",
    "plot_decision_regions(X_test, np.array(y_test).astype(np.int_), clf=model_rbf, legend=2)\n",
    "plt.show()\n",
    "\n",
    "model_lin =  SVC(kernel='linear')\n",
    "model_lin.fit(X_train, y_train)\n",
    "plot_decision_regions(X_train, np.array(y_train).astype(np.int_), clf=model_lin, legend=2)\n",
    "plt.show()\n",
    "\n",
    "y_pred = model_lin.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1_round =  round(f1, 2) \n",
    "print(\"F1 score lin: \", f1_round)\n",
    "plot_decision_regions(X_test, np.array(y_test).astype(np.int_), clf=model_lin, legend=2)\n",
    "plt.show()\n",
    "\n",
    "model_poly =  SVC(kernel='poly')\n",
    "model_poly.fit(X_train, y_train)\n",
    "plot_decision_regions(X_train, np.array(y_train).astype(np.int_), clf=model_poly, legend=2)\n",
    "plt.show()\n",
    "\n",
    "y_pred = model_poly.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1_round =  round(f1, 2) \n",
    "print(\"F1 score poly: \", f1_round)\n",
    "plot_decision_regions(X_test, np.array(y_test).astype(np.int_), clf=model_poly, legend=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# General classification (all subjects with 1 model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def gen_classification(subjects, threshold, segment_length, test_subjects, subject_test_split=False):\n",
    "    if subject_test_split:\n",
    "        subjects = list(map(str, subjects))\n",
    "        if test_subjects:\n",
    "            test_subs = list(map(str, test_subjects))\n",
    "        else:\n",
    "            num_test_subs = int(0.3 * len(subjects))\n",
    "            test_subs = random.sample(subjects, k=num_test_subs)\n",
    "        train_subs = list((Counter(subjects)-Counter(test_subs)).elements())\n",
    "        print(train_subs)\n",
    "        print(test_subs)\n",
    "        \n",
    "        first = True\n",
    "        for sub in train_subs:\n",
    "            subject = 'subject' + sub\n",
    "            if first:\n",
    "                X_normal_train, X_sleepy_train = get_data(subject, threshold, segment_length)\n",
    "                X_normal_train = np.array(X_normal_train)\n",
    "                X_sleepy_train = np.array(X_sleepy_train)\n",
    "                first = False\n",
    "            else:\n",
    "                new_X_normal, new_X_sleepy = get_data(subject, threshold, segment_length)\n",
    "                X_normal_train = np.concatenate((X_normal_train, np.array(new_X_normal)), axis=0)\n",
    "                X_sleepy_train = np.concatenate((X_sleepy_train, np.array(new_X_sleepy)), axis=0)\n",
    "       \n",
    "        first = True\n",
    "        for sub in test_subs:\n",
    "            subject = 'subject' + sub\n",
    "            if first:\n",
    "                X_normal_test, X_sleepy_test = get_data(subject, threshold, segment_length)\n",
    "                X_normal_test = np.array(X_normal_test)\n",
    "                X_sleepy_test = np.array(X_sleepy_test)\n",
    "                first = False\n",
    "            else:\n",
    "                new_X_normal, new_X_sleepy = get_data(subject, threshold, segment_length)\n",
    "                X_normal_test = np.concatenate((X_normal_test, np.array(new_X_normal)), axis=0)\n",
    "                X_sleepy_test = np.concatenate((X_sleepy_test, np.array(new_X_sleepy)), axis=0)\n",
    "        \n",
    "        y_normal_train = list(np.zeros(len(X_normal_train)))\n",
    "        y_normal_test = list(np.zeros(len(X_normal_test)))\n",
    "        \n",
    "        y_sleepy_train = list(np.ones(len(X_sleepy_train)))\n",
    "        y_sleepy_test = list(np.ones(len(X_sleepy_test)))\n",
    "        \n",
    "          \n",
    "        X_normal = X_normal_train.tolist() + X_normal_test.tolist()\n",
    "        X_sleepy = X_sleepy_train.tolist() + X_sleepy_test.tolist()\n",
    "        \n",
    "        X = X_normal + X_sleepy\n",
    "         \n",
    "        train_normal_end = len(X_normal_train)\n",
    "        test_normal_end = len(X_normal_test) + train_normal_end\n",
    "        \n",
    "        train_sleepy_end = len(X_sleepy_train) + test_normal_end\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        X_norm = scaler.fit_transform(X)\n",
    "        \n",
    "        norm_X_normal_train = X_norm[:train_normal_end]\n",
    "        norm_X_normal_test = X_norm[train_normal_end:test_normal_end]\n",
    "        norm_X_sleepy_train = X_norm[test_normal_end:train_sleepy_end]\n",
    "        norm_X_sleepy_test = X_norm[train_sleepy_end:]\n",
    "\n",
    "        print(len(X_normal_train), len(norm_X_normal_train))\n",
    "        print(len(X_normal_test), len(norm_X_normal_test))\n",
    "        print(len(X_sleepy_train), len(norm_X_sleepy_train))\n",
    "        print(len(X_sleepy_test), len(norm_X_sleepy_test))\n",
    "        \n",
    "        y_train = y_normal_train + y_sleepy_train\n",
    "        y_test = y_normal_test + y_sleepy_test\n",
    "        \n",
    "        X_train = norm_X_normal_train.tolist() + norm_X_sleepy_train.tolist()\n",
    "        X_test = norm_X_normal_test.tolist() + norm_X_sleepy_test.tolist()\n",
    "        \n",
    "        # train model\n",
    "        model = SVC(kernel='poly')\n",
    "        model.fit(np.array(X_train), y_train)\n",
    "\n",
    "        y_pred = model.predict(np.array(X_test))\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1_round =  round(f1, 2) \n",
    "        print(\"F1 score: \", f1_round)\n",
    "        return model, f1_round, X_train, X_test, y_train, y_test\n",
    "        \n",
    "    else:\n",
    "        first = True\n",
    "        for sub in subjects:\n",
    "            subject = 'subject' + str(sub)\n",
    "            if first:\n",
    "                X_normal, X_sleepy = get_data(subject, threshold, segment_length)\n",
    "                X_normal = np.array(X_normal)\n",
    "                X_sleepy = np.array(X_sleepy)\n",
    "                first = False\n",
    "            else:\n",
    "                new_X_normal, new_X_sleepy = get_data(subject, treshhold, segment_length)\n",
    "                X_normal = np.concatenate((X_normal, np.array(new_X_normal)), axis=0)\n",
    "                X_sleepy = np.concatenate((X_sleepy, np.array(new_X_sleepy)), axis=0)\n",
    "                \n",
    "        model, f1_round, X_train, X_test, y_train, y_test =  train_model(X_normal, X_sleepy)  \n",
    "        return model, f1_round, X_train, X_test, y_train, y_test\n",
    "\n",
    "def k_fold_class(k, subjects, threshold, seg_len, test_subjects=None, subject_test_split=True,):\n",
    "    sum_f1 = 0\n",
    "    for i in range(k):\n",
    "        model, f1_round, X_train, X_test, y_train, y_test = gen_classification(subjects, threshold, seg_len, test_subjects, subject_test_split=True)\n",
    "        sum_f1 += f1_round\n",
    "    return sum_f1 / k\n",
    "    \n",
    "\n",
    "subjects = [9,10, 11, 12, 14,15,16,20,23,24, 25]\n",
    "test_subjects = [10, 15, 12]\n",
    "\n",
    "subjects_trend1 = [3,4,9,10,14,15,23,24]\n",
    "subjects_trend2 = [1]\n",
    "subjects_trend3 = [7, 16, 20, 25]\n",
    "subjects_trend4 = [11, 12, 22]\n",
    "\n",
    "threshold = 10\n",
    "seg_len = 2760\n",
    "\n",
    "#model, f1_round, X_train, X_test, y_train, y_test = gen_classification(subjects_trend1, threshold, seg_len, subject_test_split=True)\n",
    "f1 = k_fold_class(1, subjects, threshold, seg_len, test_subjects, subject_test_split=True)\n",
    "print(\"Average F1 score \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Statistical Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def wilcoxon_test(normal_vals, sleepy_vals):\n",
    "    w_score = stats.wilcoxon(normal_vals, sleepy_vals)\n",
    "    return w_score[0], w_score[1]\n",
    "\n",
    "\n",
    "def equally_sized_lists(list1, list2):\n",
    "    if len(list1) > len(list2):\n",
    "        list1 = list1[:len(list2)]\n",
    "    elif len(list1) < len(list2):\n",
    "        list2 = list2[:len(list1)]\n",
    "    return list1, list2\n",
    "\n",
    "def wilcoxon_check(subjects, treshhold, segment_length):\n",
    "    sum_score = 0\n",
    "    w_scores = []\n",
    "    for sub in subjects:\n",
    "        subject = 'subject' + str(sub)\n",
    "        status_rates_sleepy, wrong_frames_sleepy = load_blinks(subject, 'sleepy') \n",
    "        status_rates_normal, wrong_frames_normal = load_blinks(subject, 'normal') \n",
    "        blink_counts_normal, average_durs_normal = run_analysis(status_rates_normal, wrong_frames_normal, treshhold, segment_length)\n",
    "        blink_counts_sleepy, average_durs_sleepy = run_analysis(status_rates_sleepy, wrong_frames_sleepy, treshhold, segment_length)\n",
    "    \n",
    "        blink_counts_normal, blink_counts_sleepy = equally_sized_lists(blink_counts_normal, blink_counts_sleepy)\n",
    "        average_durs_normal, average_durs_sleepy = equally_sized_lists(average_durs_normal, average_durs_sleepy)\n",
    "        normal_concat = np.concatenate((blink_counts_normal, average_durs_normal))\n",
    "        sleepy_concat = np.concatenate((blink_counts_sleepy, average_durs_sleepy))\n",
    "        print(normal_concat.shape, sleepy_concat.shape)\n",
    "        w_score = wilcoxon_test(normal_concat, sleepy_concat)\n",
    "        sum_score += w_score[1]\n",
    "        print(w_score[1])\n",
    "        w_scores.append(w_score[1])\n",
    "        print(\"Done with subject \" + str(sub))\n",
    "\n",
    "    print(\"mean: \", np.mean(np.array(w_scores)))\n",
    "    return (sum_score / len(subjects)), w_scores\n",
    "\n",
    "subjects = [1,3,4,6,7,14,15,16,20,23,24]\n",
    "avg_wil, w_scores = wilcoxon_check(subjects, 10, 46 * 60)\n",
    "print(\"Average wilcoxon p-value for the first two principal components combined: \", avg_wil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
