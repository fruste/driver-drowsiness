{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6abcbf6-8bef-4423-beb9-960a57dc5d56",
   "metadata": {},
   "source": [
    "# Temporal models \n",
    "Several temporal with the derived features as input, predicting a binary sleep deprivation label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57916f02-9379-471c-b5ee-3c0f6ad50e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5e8b6b-b209-4e37-8fe4-6f70d479ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe20f1-0864-435b-ae54-3a82af6f6c35",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1960e29b-ff82-4c2f-b56c-329340f82145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(subject):\n",
    "    path = '../embeddings/embeddings_' + subject\n",
    "    normal_embs = np.load(path + '_normal.npy')\n",
    "    sleepy_embs = np.load(path + '_sleepy.npy')\n",
    "\n",
    "    return normal_embs, sleepy_embs\n",
    "\n",
    "def load_multi_embeddings(subjects):\n",
    "    normal_dict = {}\n",
    "    sleepy_dict = {}\n",
    "\n",
    "    for sub in subjects:\n",
    "        path = '../embeddings/embeddings_sub' + str(sub)\n",
    "        normal_frames = np.load(path + '_normal.npy')\n",
    "        sleepy_frames = np.load(path + '_sleepy.npy')\n",
    "\n",
    "        normal_dict[str(sub)] = normal_frames\n",
    "        sleepy_dict[str(sub)] = sleepy_frames\n",
    "\n",
    "    return normal_dict, sleepy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd569b8d-a68b-4050-b255-ae890bcc3e6f",
   "metadata": {},
   "source": [
    "## First model: GRU deep features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f628ea07-9570-41ec-85c7-2df0cd68942b",
   "metadata": {},
   "source": [
    "### Model initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630324e1-d991-4099-8a21-e7e74a06b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78e999b-ba8c-49d6-bcb2-c1f083806e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "class DrowsinessDetector:\n",
    "    def __init__(self, segment_length):\n",
    "        self.segment_length = segment_length\n",
    "        self.input_shape = (self.segment_length, 2048)\n",
    "        \n",
    "    def split_frames(self, frames):\n",
    "        num_segments = len(frames) // self.segment_length\n",
    "        frames = frames[:num_segments * self.segment_length]\n",
    "        return np.array(np.split(frames, num_segments))\n",
    "    \n",
    "    def create_labels(self, num_segments, label):\n",
    "        return np.array([label] * num_segments)\n",
    "    \n",
    "    def shuffle_data(self, X, y):\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def construct_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(SimpleRNN(32, input_shape=self.input_shape))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_data_one_sub(self, normal_frames, sleepy_frames):\n",
    "        X_normal = self.split_frames(normal_frames)\n",
    "        y_normal = self.create_labels(len(X_normal), 0)\n",
    "        X_sleepy = self.split_frames(sleepy_frames)\n",
    "        y_sleepy = self.create_labels(len(X_sleepy), 1)\n",
    "        X = np.concatenate((X_normal, X_sleepy))\n",
    "        y = np.concatenate((y_normal, y_sleepy))\n",
    "        X, y = self.shuffle_data(X, y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def get_data_multi_sub(self, normal_frames_dict, sleepy_frames_dict, leave_out_ratio=0.3):\n",
    "            subjects = list(normal_frames_dict.keys())\n",
    "            leave_out_subjects = np.random.choice(subjects, int(len(subjects) * leave_out_ratio), replace=False)\n",
    "            print(\"Test subjects\", leave_out_subjects)\n",
    "\n",
    "            X_train, y_train = None, None\n",
    "            for subject in subjects:\n",
    "                if subject in leave_out_subjects:\n",
    "                    continue\n",
    "                print('train', subject)\n",
    "                frames = normal_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 0)\n",
    "                if X_train is None:\n",
    "                    X_train, y_train = X, y\n",
    "                else:\n",
    "                    X_train = np.concatenate((X_train, X))\n",
    "                    y_train = np.concatenate((y_train, y))\n",
    "\n",
    "                frames = sleepy_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 1)\n",
    "                X_train = np.concatenate((X_train, X))\n",
    "                y_train = np.concatenate((y_train, y))\n",
    "\n",
    "            X_test, y_test = None, None\n",
    "            for subject in leave_out_subjects:\n",
    "                print('test', subject)\n",
    "                frames = normal_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 0)\n",
    "\n",
    "                if X_test is None:\n",
    "                    X_test, y_test = X, y\n",
    "                else:\n",
    "                    X_test = np.concatenate((X_test, X))\n",
    "                    y_test = np.concatenate((y_test, y))\n",
    "                    \n",
    "                frames = sleepy_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 1)\n",
    "                \n",
    "                X_test = np.concatenate((X_test, X))\n",
    "                y_test = np.concatenate((y_test, y))\n",
    "\n",
    "            X_train, y_train = self.shuffle_data(X_train, y_train)\n",
    "            X_test, y_test = self.shuffle_data(X_test, y_test)\n",
    "\n",
    "            return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train(self, X_train, y_train, num_epochs=10, batch_size=32, validation_split=0.2):\n",
    "        self.batch_size = batch_size\n",
    "        model = self.construct_model()\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=validation_split, callbacks=[early_stop])\n",
    "        \n",
    "        self.model = model\n",
    "        print(\"Done with training\")\n",
    "        return model\n",
    "    \n",
    "    def test(self, X_test, y_test):\n",
    "        model = self.model\n",
    "        return model.evaluate(X_test, y_test, batch_size=self.batch_size)\n",
    "    \n",
    "    def get_f1(self, X_test, y_test):\n",
    "        y_predict = model.predict(X_test, batch_size = self.batch_size)\n",
    "        y_predict_int = np.round(y_predict).astype(int).flatten()\n",
    "        f1 = f1_score(y_test, y_predict_int)\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56916945-fea1-4162-a5ff-614b6683aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subjects ['10' '15' '12']\n",
      "train 9\n",
      "train 11\n",
      "train 14\n",
      "train 16\n",
      "train 20\n",
      "train 23\n",
      "train 24\n",
      "train 25\n",
      "test 10\n",
      "test 15\n",
      "test 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 14:34:54.336363: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-30 14:34:55.376284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20675 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:85:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 90s 2s/step - loss: 0.7288 - accuracy: 0.6458 - val_loss: 0.4392 - val_accuracy: 0.7963\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.5048 - accuracy: 0.7477 - val_loss: 0.3631 - val_accuracy: 0.8889\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 86s 2s/step - loss: 0.4242 - accuracy: 0.8009 - val_loss: 0.2873 - val_accuracy: 0.9167\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 85s 2s/step - loss: 0.3475 - accuracy: 0.8519 - val_loss: 0.2638 - val_accuracy: 0.9074\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.3273 - accuracy: 0.8495 - val_loss: 0.2246 - val_accuracy: 0.9630\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 82s 2s/step - loss: 0.3018 - accuracy: 0.8519 - val_loss: 0.2183 - val_accuracy: 0.9630\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 81s 2s/step - loss: 0.2856 - accuracy: 0.8796 - val_loss: 0.2606 - val_accuracy: 0.9444\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 80s 1s/step - loss: 0.2956 - accuracy: 0.8843 - val_loss: 0.1795 - val_accuracy: 0.9167\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 80s 1s/step - loss: 0.2138 - accuracy: 0.9074 - val_loss: 0.1677 - val_accuracy: 0.9167\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 80s 1s/step - loss: 0.2064 - accuracy: 0.9259 - val_loss: 0.1140 - val_accuracy: 0.9815\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 81s 2s/step - loss: 0.1995 - accuracy: 0.9190 - val_loss: 0.1377 - val_accuracy: 0.9815\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 79s 1s/step - loss: 0.1889 - accuracy: 0.9398 - val_loss: 0.1421 - val_accuracy: 0.9815\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 80s 1s/step - loss: 0.1754 - accuracy: 0.9375 - val_loss: 0.1127 - val_accuracy: 0.9722\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 82s 2s/step - loss: 0.1767 - accuracy: 0.9329 - val_loss: 0.1145 - val_accuracy: 0.9722\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 82s 2s/step - loss: 0.1554 - accuracy: 0.9468 - val_loss: 0.1116 - val_accuracy: 0.9722\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 81s 2s/step - loss: 0.1505 - accuracy: 0.9352 - val_loss: 0.0921 - val_accuracy: 0.9722\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 81s 2s/step - loss: 0.1284 - accuracy: 0.9537 - val_loss: 0.0914 - val_accuracy: 0.9815\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 80s 1s/step - loss: 0.1368 - accuracy: 0.9583 - val_loss: 0.1018 - val_accuracy: 0.9630\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 80s 1s/step - loss: 0.1535 - accuracy: 0.9421 - val_loss: 0.0815 - val_accuracy: 0.9815\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 79s 1s/step - loss: 0.0881 - accuracy: 0.9745 - val_loss: 0.0731 - val_accuracy: 0.9722\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 81s 2s/step - loss: 0.1041 - accuracy: 0.9630 - val_loss: 0.0640 - val_accuracy: 0.9815\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 79s 1s/step - loss: 0.1085 - accuracy: 0.9630 - val_loss: 0.0815 - val_accuracy: 0.9722\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 79s 1s/step - loss: 0.0904 - accuracy: 0.9722 - val_loss: 0.0815 - val_accuracy: 0.9722\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 78s 1s/step - loss: 0.0935 - accuracy: 0.9745 - val_loss: 0.0712 - val_accuracy: 0.9722\n",
      "Epoch 00024: early stopping\n",
      "Done with training\n"
     ]
    }
   ],
   "source": [
    "detector = DrowsinessDetector(segment_length=60 * 46)\n",
    "#normal_embs, sleepy_embs = load_embeddings('sub10')\n",
    "#X_train, X_test, y_train, y_test = detector.get_data_one_sub(normal_embs, sleepy_embs)\n",
    "\n",
    "subjects = [9,10, 11, 12, 14,15,16,20,23,24, 25]\n",
    "\n",
    "#subjects = [1,3,4,6]\n",
    "normal_dict, sleepy_dict = load_multi_embeddings(subjects)\n",
    "X_train, X_test, y_train, y_test = detector.get_data_multi_sub(normal_dict, sleepy_dict)\n",
    "\n",
    "model = detector.train(X_train, y_train, num_epochs=100, batch_size=8)\n",
    "#detector.test(X_test, y_test)\n",
    "#y_test, y_predict = detector.compare_predictions(X_test, y_test)\n",
    "#print(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562d1859-ddde-47f3-bb55-71bcbb2f2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# y_predict = model.predict(X_test)\n",
    "# y_predict_int = np.round(y_predict).astype(int).flatten()\n",
    "# f1 = f1_score(y_test, y_predict_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796514d1-d9f0-4a58-98dd-abdfbfa99bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5238095238095237\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "f1 = detector.get_f1(X_test, y_test)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7c3a24-1eef-480f-be12-71d1f56d039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5040650406504066\n"
     ]
    }
   ],
   "source": [
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd782d7-ea64-4896-952f-f8b577a6ca30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
