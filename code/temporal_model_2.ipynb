{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6abcbf6-8bef-4423-beb9-960a57dc5d56",
   "metadata": {},
   "source": [
    "# Temporal model Deep GRU + Shallow GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57916f02-9379-471c-b5ee-3c0f6ad50e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a5e8b6b-b209-4e37-8fe4-6f70d479ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe20f1-0864-435b-ae54-3a82af6f6c35",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1960e29b-ff82-4c2f-b56c-329340f82145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(subject):\n",
    "    path = '../embeddings/embeddings_' + subject\n",
    "    normal_embs = np.load(path + '_normal.npy')\n",
    "    sleepy_embs = np.load(path + '_sleepy.npy')\n",
    "\n",
    "    return normal_embs, sleepy_embs\n",
    "\n",
    "def load_multi_embeddings(subjects):\n",
    "    normal_dict = {}\n",
    "    sleepy_dict = {}\n",
    "\n",
    "    for sub in subjects:\n",
    "        path = '../embeddings/embeddings_sub' + str(sub)\n",
    "        normal_frames = np.load(path + '_normal.npy')\n",
    "        sleepy_frames = np.load(path + '_sleepy.npy')\n",
    "\n",
    "        normal_dict[str(sub)] = normal_frames\n",
    "        sleepy_dict[str(sub)] = sleepy_frames\n",
    "\n",
    "    return normal_dict, sleepy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd569b8d-a68b-4050-b255-ae890bcc3e6f",
   "metadata": {},
   "source": [
    "## First model: GRU deep features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f628ea07-9570-41ec-85c7-2df0cd68942b",
   "metadata": {},
   "source": [
    "### Model initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "630324e1-d991-4099-8a21-e7e74a06b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d78e999b-ba8c-49d6-bcb2-c1f083806e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "class DrowsinessDetector:\n",
    "    def __init__(self, segment_length):\n",
    "        self.segment_length = segment_length\n",
    "        self.input_shape = (self.segment_length, 2048)\n",
    "        \n",
    "    def split_frames(self, frames):\n",
    "        num_segments = len(frames) // self.segment_length\n",
    "        frames = frames[:num_segments * self.segment_length]\n",
    "        return np.array(np.split(frames, num_segments))\n",
    "    \n",
    "    def create_labels(self, num_segments, label):\n",
    "        return np.array([label] * num_segments)\n",
    "    \n",
    "    def shuffle_data(self, X, y):\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def construct_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(SimpleRNN(32, input_shape=self.input_shape))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_deep_data(self, normal_frames_dict, sleepy_frames_dict, subjects, leave_out_subjects):\n",
    "            X_train, y_train = None, None\n",
    "            for subject in subjects:\n",
    "                if subject in leave_out_subjects:\n",
    "                    continue\n",
    "                print('train', subject)\n",
    "                frames = normal_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                print(X.shape)\n",
    "                assert 0\n",
    "                y = self.create_labels(len(X), 0)\n",
    "                if X_train is None:\n",
    "                    X_train, y_train = X, y\n",
    "                else:\n",
    "                    X_train = np.concatenate((X_train, X))\n",
    "                    y_train = np.concatenate((y_train, y))\n",
    "\n",
    "                frames = sleepy_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 1)\n",
    "                X_train = np.concatenate((X_train, X))\n",
    "                y_train = np.concatenate((y_train, y))\n",
    "\n",
    "            X_test, y_test = None, None\n",
    "            for subject in leave_out_subjects:\n",
    "                print('test', subject)\n",
    "                frames = normal_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 0)\n",
    "\n",
    "                if X_test is None:\n",
    "                    X_test, y_test = X, y\n",
    "                else:\n",
    "                    X_test = np.concatenate((X_test, X))\n",
    "                    y_test = np.concatenate((y_test, y))\n",
    "                    \n",
    "                frames = sleepy_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 1)\n",
    "                \n",
    "                X_test = np.concatenate((X_test, X))\n",
    "                y_test = np.concatenate((y_test, y))\n",
    "\n",
    "            X_train, y_train = self.shuffle_data(X_train, y_train)\n",
    "            X_test, y_test = self.shuffle_data(X_test, y_test)\n",
    "\n",
    "            return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def get_shallow_data_multi_sub(self, normal_frames_dict, leave_out_ratio=0.3):\n",
    "            subjects = list(normal_frames_dict.keys())\n",
    "            leave_out_subjects = np.random.choice(subjects, int(len(subjects) * leave_out_ratio), replace=False)\n",
    "            print(\"Test subjects\", leave_out_subjects)\n",
    "\n",
    "            X_train, y_train = None, None\n",
    "            for subject in subjects:\n",
    "                if subject in leave_out_subjects:\n",
    "                    continue\n",
    "                frames = normal_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                print(X.shape)\n",
    "                assert 0\n",
    "                y = self.create_labels(len(X), 0)\n",
    "                if X_train is None:\n",
    "                    X_train, y_train = X, y\n",
    "                else:\n",
    "                    X_train = np.concatenate((X_train, X))\n",
    "                    y_train = np.concatenate((y_train, y))\n",
    "\n",
    "                frames = sleepy_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 1)\n",
    "                X_train = np.concatenate((X_train, X))\n",
    "                y_train = np.concatenate((y_train, y))\n",
    "\n",
    "            X_test, y_test = None, None\n",
    "            for subject in leave_out_subjects:\n",
    "                print('test', subject)\n",
    "                frames = normal_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 0)\n",
    "\n",
    "                if X_test is None:\n",
    "                    X_test, y_test = X, y\n",
    "                else:\n",
    "                    X_test = np.concatenate((X_test, X))\n",
    "                    y_test = np.concatenate((y_test, y))\n",
    "                    \n",
    "                frames = sleepy_frames_dict[subject]\n",
    "                X = self.split_frames(frames)\n",
    "                y = self.create_labels(len(X), 1)\n",
    "                \n",
    "                X_test = np.concatenate((X_test, X))\n",
    "                y_test = np.concatenate((y_test, y))\n",
    "\n",
    "            X_train, y_train = self.shuffle_data(X_train, y_train)\n",
    "            X_test, y_test = self.shuffle_data(X_test, y_test)\n",
    "\n",
    "            return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train(self, X_train, y_train, num_epochs=10, batch_size=32, validation_split=0.2):\n",
    "        self.batch_size = batch_size\n",
    "        model = self.construct_model()\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=validation_split, callbacks=[early_stop])\n",
    "        \n",
    "        self.model = model\n",
    "        print(\"Done with training\")\n",
    "        return model\n",
    "    \n",
    "    def test(self, X_test, y_test):\n",
    "        model = self.model\n",
    "        return model.evaluate(X_test, y_test, batch_size=self.batch_size)\n",
    "    \n",
    "    def get_f1(self, X_test, y_test):\n",
    "        y_predict = model.predict(X_test, batch_size = self.batch_size)\n",
    "        y_predict_int = np.round(y_predict).astype(int).flatten()\n",
    "        f1 = f1_score(y_test_int, y_predict_int)\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56916945-fea1-4162-a5ff-614b6683aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subjects ['15' '23' '16']\n",
      "train 1\n",
      "(62, 2760, 2048)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#subjects = [1,3,4,6]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m normal_dict, sleepy_dict \u001b[38;5;241m=\u001b[39m load_multi_embeddings(subjects)\n\u001b[0;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_multi_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msleepy_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mDrowsinessDetector.get_data_multi_sub\u001b[0;34m(self, normal_frames_dict, sleepy_frames_dict, leave_out_ratio)\u001b[0m\n\u001b[1;32m     56\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_frames(frames)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     59\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_labels(\u001b[38;5;28mlen\u001b[39m(X), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "detector = DrowsinessDetector(segment_length=60 * 46)\n",
    "#normal_embs, sleepy_embs = load_embeddings('sub10')\n",
    "#X_train, X_test, y_train, y_test = detector.get_data_one_sub(normal_embs, sleepy_embs)\n",
    "\n",
    "subjects = [1,3,4,6,7,9,14,15,16,20,23,24]\n",
    "\n",
    "leave_out_ratio = 0.3\n",
    "leave_out_subjects = np.random.choice(subjects, int(len(subjects) * leave_out_ratio), replace=False)\n",
    "\n",
    "normal_dict, sleepy_dict = load_multi_embeddings(subjects)\n",
    "X_deep_train, X_deep_test, y_train, y_test = detector.get_deep_data(normal_dict, sleepy_dict, subjects, leave_out_subjects)\n",
    "\n",
    "model = detector.train(X_train, y_train, num_epochs=100, batch_size=8)\n",
    "#detector.test(X_test, y_test)\n",
    "#y_test, y_predict = detector.compare_predictions(X_test, y_test)\n",
    "#print(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796514d1-d9f0-4a58-98dd-abdfbfa99bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "f1 = detector.get_f1(X_test, y_test)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb11cf-7ed7-430b-999d-4fd8b6a611d1",
   "metadata": {},
   "source": [
    "## Shallow data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6968724-4212-4855-b645-0c484dfc267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting segmenting normal condition\n",
      "Number of segments 353\n",
      "Starting segmenting sleepy condition\n",
      "Number of segments 325\n",
      "(58, 6, 2)\n",
      "[[[ 6.          1.66666667]\n",
      "  [ 6.          2.33333333]\n",
      "  [ 7.          2.28571429]\n",
      "  [ 5.          2.        ]\n",
      "  [ 7.          1.57142857]\n",
      "  [11.          2.09090909]]\n",
      "\n",
      " [[13.          1.84615385]\n",
      "  [12.          2.41666667]\n",
      "  [11.          1.90909091]\n",
      "  [11.          1.90909091]\n",
      "  [13.          2.15384615]\n",
      "  [ 7.          2.14285714]]\n",
      "\n",
      " [[14.          2.14285714]\n",
      "  [17.          2.76470588]\n",
      "  [16.          2.        ]\n",
      "  [27.          3.25925926]\n",
      "  [34.          2.85294118]\n",
      "  [27.          2.62962963]]\n",
      "\n",
      " [[30.          3.1       ]\n",
      "  [17.          1.47058824]\n",
      "  [27.          2.        ]\n",
      "  [16.          1.25      ]\n",
      "  [19.          2.15789474]\n",
      "  [19.          3.21052632]]\n",
      "\n",
      " [[11.          2.72727273]\n",
      "  [12.          2.        ]\n",
      "  [12.          1.83333333]\n",
      "  [11.          2.        ]\n",
      "  [14.          2.28571429]\n",
      "  [12.          2.        ]]\n",
      "\n",
      " [[ 9.          2.44444444]\n",
      "  [ 9.          2.88888889]\n",
      "  [12.          3.25      ]\n",
      "  [ 6.          2.66666667]\n",
      "  [11.          3.09090909]\n",
      "  [ 6.          2.16666667]]\n",
      "\n",
      " [[ 7.          2.85714286]\n",
      "  [ 9.          1.88888889]\n",
      "  [ 5.          1.8       ]\n",
      "  [ 5.          3.        ]\n",
      "  [ 7.          3.28571429]\n",
      "  [ 8.          2.25      ]]\n",
      "\n",
      " [[ 9.          3.        ]\n",
      "  [ 9.          2.66666667]\n",
      "  [12.          2.41666667]\n",
      "  [ 8.          2.125     ]\n",
      "  [ 6.          2.        ]\n",
      "  [ 8.          3.125     ]]\n",
      "\n",
      " [[ 9.          3.33333333]\n",
      "  [ 7.          2.57142857]\n",
      "  [ 6.          2.83333333]\n",
      "  [ 7.          1.71428571]\n",
      "  [ 9.          2.22222222]\n",
      "  [ 9.          3.        ]]\n",
      "\n",
      " [[ 8.          2.625     ]\n",
      "  [13.          3.61538462]\n",
      "  [ 5.          2.6       ]\n",
      "  [10.          2.7       ]\n",
      "  [10.          3.1       ]\n",
      "  [ 6.          3.        ]]\n",
      "\n",
      " [[ 9.          3.44444444]\n",
      "  [12.          2.91666667]\n",
      "  [ 7.          3.42857143]\n",
      "  [12.          3.91666667]\n",
      "  [ 4.          3.5       ]\n",
      "  [ 6.          3.        ]]\n",
      "\n",
      " [[ 7.          3.        ]\n",
      "  [ 9.          2.88888889]\n",
      "  [ 3.          2.66666667]\n",
      "  [ 5.          2.6       ]\n",
      "  [11.          3.81818182]\n",
      "  [ 7.          3.28571429]]\n",
      "\n",
      " [[ 8.          2.75      ]\n",
      "  [ 7.          3.        ]\n",
      "  [ 5.          2.2       ]\n",
      "  [ 8.          2.625     ]\n",
      "  [ 6.          1.66666667]\n",
      "  [ 6.          2.16666667]]\n",
      "\n",
      " [[ 6.          2.        ]\n",
      "  [ 8.          2.125     ]\n",
      "  [ 6.          3.        ]\n",
      "  [11.          2.45454545]\n",
      "  [ 9.          2.44444444]\n",
      "  [ 9.          2.33333333]]\n",
      "\n",
      " [[ 5.          2.8       ]\n",
      "  [10.          2.5       ]\n",
      "  [10.          2.8       ]\n",
      "  [10.          2.8       ]\n",
      "  [ 8.          2.75      ]\n",
      "  [ 7.          3.14285714]]\n",
      "\n",
      " [[12.          2.58333333]\n",
      "  [ 7.          2.85714286]\n",
      "  [11.          2.90909091]\n",
      "  [12.          3.08333333]\n",
      "  [11.          3.09090909]\n",
      "  [10.          3.8       ]]\n",
      "\n",
      " [[ 9.          3.        ]\n",
      "  [12.          3.16666667]\n",
      "  [12.          3.25      ]\n",
      "  [ 7.          3.        ]\n",
      "  [ 9.          3.33333333]\n",
      "  [10.          2.3       ]]\n",
      "\n",
      " [[ 8.          2.25      ]\n",
      "  [11.          3.18181818]\n",
      "  [ 7.          3.        ]\n",
      "  [ 9.          1.88888889]\n",
      "  [ 9.          1.66666667]\n",
      "  [10.          2.6       ]]\n",
      "\n",
      " [[10.          2.3       ]\n",
      "  [ 7.          2.85714286]\n",
      "  [ 9.          1.77777778]\n",
      "  [ 7.          1.71428571]\n",
      "  [11.          2.45454545]\n",
      "  [11.          2.45454545]]\n",
      "\n",
      " [[ 9.          2.77777778]\n",
      "  [12.          2.66666667]\n",
      "  [11.          2.81818182]\n",
      "  [ 7.          2.85714286]\n",
      "  [ 9.          3.66666667]\n",
      "  [12.          2.41666667]]\n",
      "\n",
      " [[ 9.          3.44444444]\n",
      "  [ 7.          2.71428571]\n",
      "  [12.          2.75      ]\n",
      "  [10.          3.1       ]\n",
      "  [11.          3.54545455]\n",
      "  [ 6.          3.        ]]\n",
      "\n",
      " [[ 4.          2.75      ]\n",
      "  [ 9.          2.44444444]\n",
      "  [ 5.          2.6       ]\n",
      "  [11.          3.27272727]\n",
      "  [10.          3.9       ]\n",
      "  [ 8.          3.75      ]]\n",
      "\n",
      " [[ 9.          3.55555556]\n",
      "  [ 8.          4.        ]\n",
      "  [ 8.          3.5       ]\n",
      "  [ 9.          4.55555556]\n",
      "  [15.          4.        ]\n",
      "  [13.          4.76923077]]\n",
      "\n",
      " [[16.          3.5       ]\n",
      "  [13.          4.23076923]\n",
      "  [12.          5.75      ]\n",
      "  [16.          3.1875    ]\n",
      "  [ 9.          8.        ]\n",
      "  [14.          2.42857143]]\n",
      "\n",
      " [[ 4.          2.25      ]\n",
      "  [ 8.          4.25      ]\n",
      "  [12.          3.25      ]\n",
      "  [15.          4.06666667]\n",
      "  [17.          3.82352941]\n",
      "  [12.          4.58333333]]\n",
      "\n",
      " [[12.          3.41666667]\n",
      "  [11.          3.54545455]\n",
      "  [ 6.          2.83333333]\n",
      "  [ 7.          3.14285714]\n",
      "  [ 4.          1.75      ]\n",
      "  [11.          2.63636364]]\n",
      "\n",
      " [[13.          2.69230769]\n",
      "  [13.          2.84615385]\n",
      "  [10.          2.6       ]\n",
      "  [ 9.          2.77777778]\n",
      "  [10.          2.7       ]\n",
      "  [ 6.          3.        ]]\n",
      "\n",
      " [[16.          3.0625    ]\n",
      "  [14.          3.42857143]\n",
      "  [12.          3.33333333]\n",
      "  [ 9.          2.77777778]\n",
      "  [ 7.          2.85714286]\n",
      "  [ 9.          3.33333333]]\n",
      "\n",
      " [[ 9.          2.88888889]\n",
      "  [ 9.          3.22222222]\n",
      "  [15.          3.06666667]\n",
      "  [10.          3.1       ]\n",
      "  [13.          2.84615385]\n",
      "  [10.          2.8       ]]\n",
      "\n",
      " [[10.          3.1       ]\n",
      "  [ 8.          3.5       ]\n",
      "  [11.          3.        ]\n",
      "  [ 9.          3.55555556]\n",
      "  [14.          3.64285714]\n",
      "  [ 9.          3.88888889]]\n",
      "\n",
      " [[12.          2.91666667]\n",
      "  [10.          3.2       ]\n",
      "  [11.          4.09090909]\n",
      "  [10.          3.5       ]\n",
      "  [ 6.          3.33333333]\n",
      "  [ 5.          3.2       ]]\n",
      "\n",
      " [[10.          3.3       ]\n",
      "  [ 9.          3.44444444]\n",
      "  [ 8.          3.        ]\n",
      "  [14.          2.64285714]\n",
      "  [11.          3.36363636]\n",
      "  [15.          3.46666667]]\n",
      "\n",
      " [[10.          4.        ]\n",
      "  [14.          3.71428571]\n",
      "  [ 9.          3.11111111]\n",
      "  [ 8.          3.375     ]\n",
      "  [ 5.          2.8       ]\n",
      "  [11.          3.45454545]]\n",
      "\n",
      " [[10.          3.1       ]\n",
      "  [ 9.          2.33333333]\n",
      "  [ 8.          2.5       ]\n",
      "  [ 7.          3.14285714]\n",
      "  [ 6.          2.5       ]\n",
      "  [10.          2.        ]]\n",
      "\n",
      " [[ 7.          2.28571429]\n",
      "  [ 8.          2.25      ]\n",
      "  [ 7.          2.14285714]\n",
      "  [10.          2.7       ]\n",
      "  [12.          2.75      ]\n",
      "  [25.          2.92      ]]\n",
      "\n",
      " [[15.          2.86666667]\n",
      "  [15.          4.06666667]\n",
      "  [16.          3.625     ]\n",
      "  [15.          4.6       ]\n",
      "  [13.          3.30769231]\n",
      "  [15.          3.        ]]\n",
      "\n",
      " [[15.          3.6       ]\n",
      "  [12.          3.66666667]\n",
      "  [16.          3.5625    ]\n",
      "  [13.          3.69230769]\n",
      "  [13.          5.07692308]\n",
      "  [21.          3.0952381 ]]\n",
      "\n",
      " [[14.          4.14285714]\n",
      "  [22.          3.59090909]\n",
      "  [16.          4.6875    ]\n",
      "  [16.          4.125     ]\n",
      "  [10.          3.6       ]\n",
      "  [12.          7.        ]]\n",
      "\n",
      " [[ 3.          4.33333333]\n",
      "  [ 2.          4.        ]\n",
      "  [11.          4.90909091]\n",
      "  [11.          4.18181818]\n",
      "  [17.          4.58823529]\n",
      "  [12.          6.5       ]]\n",
      "\n",
      " [[13.          4.15384615]\n",
      "  [13.          7.61538462]\n",
      "  [21.         16.61904762]\n",
      "  [24.         15.58333333]\n",
      "  [ 9.         22.44444444]\n",
      "  [ 6.         33.66666667]]\n",
      "\n",
      " [[15.         16.53333333]\n",
      "  [ 8.         32.5       ]\n",
      "  [ 7.         17.42857143]\n",
      "  [ 2.          1.        ]\n",
      "  [ 6.          3.66666667]\n",
      "  [ 9.          3.33333333]]\n",
      "\n",
      " [[10.          3.        ]\n",
      "  [ 9.          2.55555556]\n",
      "  [13.          4.15384615]\n",
      "  [ 8.          3.        ]\n",
      "  [11.          3.        ]\n",
      "  [12.          3.16666667]]\n",
      "\n",
      " [[10.          3.5       ]\n",
      "  [16.          3.5       ]\n",
      "  [13.          3.61538462]\n",
      "  [14.          3.35714286]\n",
      "  [ 7.          3.71428571]\n",
      "  [ 9.          3.77777778]]\n",
      "\n",
      " [[11.          3.36363636]\n",
      "  [12.          3.91666667]\n",
      "  [ 7.          4.71428571]\n",
      "  [ 8.          3.125     ]\n",
      "  [ 5.          3.4       ]\n",
      "  [10.          2.8       ]]\n",
      "\n",
      " [[12.          3.16666667]\n",
      "  [12.          3.16666667]\n",
      "  [14.          3.64285714]\n",
      "  [ 9.          3.88888889]\n",
      "  [ 8.          3.25      ]\n",
      "  [12.          2.75      ]]\n",
      "\n",
      " [[ 9.          3.22222222]\n",
      "  [ 9.          3.44444444]\n",
      "  [10.          3.9       ]\n",
      "  [11.          3.90909091]\n",
      "  [11.          4.09090909]\n",
      "  [ 9.          3.11111111]]\n",
      "\n",
      " [[10.          3.6       ]\n",
      "  [11.          3.36363636]\n",
      "  [ 8.          2.875     ]\n",
      "  [10.          3.1       ]\n",
      "  [ 5.          2.6       ]\n",
      "  [11.          3.54545455]]\n",
      "\n",
      " [[17.          4.11764706]\n",
      "  [16.          4.375     ]\n",
      "  [14.          3.14285714]\n",
      "  [13.          2.92307692]\n",
      "  [ 9.          2.44444444]\n",
      "  [12.          3.83333333]]\n",
      "\n",
      " [[14.          3.57142857]\n",
      "  [12.          3.66666667]\n",
      "  [ 9.          3.55555556]\n",
      "  [ 9.          2.77777778]\n",
      "  [12.          3.58333333]\n",
      "  [12.          3.25      ]]\n",
      "\n",
      " [[13.          3.        ]\n",
      "  [11.          3.36363636]\n",
      "  [11.          3.63636364]\n",
      "  [10.          4.2       ]\n",
      "  [14.          3.5       ]\n",
      "  [15.          3.66666667]]\n",
      "\n",
      " [[12.          3.5       ]\n",
      "  [12.          3.5       ]\n",
      "  [ 4.          3.75      ]\n",
      "  [21.          4.14285714]\n",
      "  [ 9.          4.        ]\n",
      "  [ 6.          8.66666667]]\n",
      "\n",
      " [[10.          4.7       ]\n",
      "  [12.          2.58333333]\n",
      "  [10.          2.9       ]\n",
      "  [ 9.          2.33333333]\n",
      "  [11.          3.45454545]\n",
      "  [11.          4.        ]]\n",
      "\n",
      " [[ 9.          3.11111111]\n",
      "  [10.          3.4       ]\n",
      "  [12.          3.25      ]\n",
      "  [11.          2.72727273]\n",
      "  [11.          3.36363636]\n",
      "  [12.          3.25      ]]\n",
      "\n",
      " [[10.          3.5       ]\n",
      "  [10.          4.2       ]\n",
      "  [ 9.          4.55555556]\n",
      "  [12.          3.16666667]\n",
      "  [ 7.          2.28571429]\n",
      "  [11.          3.        ]]\n",
      "\n",
      " [[ 9.          2.55555556]\n",
      "  [ 9.          2.66666667]\n",
      "  [ 9.          2.77777778]\n",
      "  [ 9.          2.44444444]\n",
      "  [10.          2.8       ]\n",
      "  [ 9.          3.        ]]\n",
      "\n",
      " [[ 4.          2.        ]\n",
      "  [10.          3.3       ]\n",
      "  [14.          3.42857143]\n",
      "  [10.          3.4       ]\n",
      "  [10.          3.7       ]\n",
      "  [11.          3.54545455]]\n",
      "\n",
      " [[13.          2.92307692]\n",
      "  [15.          5.26666667]\n",
      "  [12.          3.83333333]\n",
      "  [11.          3.72727273]\n",
      "  [10.          4.        ]\n",
      "  [12.          4.08333333]]\n",
      "\n",
      " [[14.          3.07142857]\n",
      "  [11.          2.18181818]\n",
      "  [10.          2.2       ]\n",
      "  [ 8.          2.875     ]\n",
      "  [12.          4.08333333]\n",
      "  [ 9.          2.88888889]]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m treshhold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     31\u001b[0m segment_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m46\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mget_shallow_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreshhold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mget_shallow_data\u001b[0;34m(subjects, threshold, segment_length)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_normal_final\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_normal_final)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from helping_functions import *\n",
    "\n",
    "\n",
    "def get_data(subject, treshhold, segment_length):\n",
    "    status_rates_sleepy, wrong_frames_sleepy = load_blinks(subject, 'sleepy') \n",
    "    status_rates_normal, wrong_frames_normal = load_blinks(subject, 'normal') \n",
    "    \n",
    "    print(\"Starting segmenting normal condition\")\n",
    "    blink_counts_normal, average_durs_normal = run_analysis(status_rates_normal, wrong_frames_normal, treshhold, segment_length)\n",
    "    print(\"Starting segmenting sleepy condition\")\n",
    "    blink_counts_sleepy, average_durs_sleepy = run_analysis(status_rates_sleepy, wrong_frames_sleepy, treshhold, segment_length)\n",
    "    \n",
    "    return list(zip(blink_counts_normal, average_durs_normal)), list(zip(blink_counts_sleepy, average_durs_sleepy))\n",
    "\n",
    "def split_into_segments(frames, gru_segment_length):\n",
    "    num_segments = len(frames) // gru_segment_length\n",
    "    frames = frames[:num_segments * gru_segment_length]\n",
    "    return np.array(np.split(np.array(frames), num_segments))\n",
    "\n",
    "def get_shallow_data(subjects, threshold, segment_length):\n",
    "    for sub in subjects:\n",
    "        subject = 'subject' + str(sub)\n",
    "        X_normal, X_sleepy = get_data(subject, threshold, segment_length)\n",
    "        X_normal_final = split_into_segments(X_normal, 6)\n",
    "        print(X_normal_final.shape)\n",
    "        print(X_normal_final)\n",
    "        assert 0\n",
    "\n",
    "subjects = [1,3,4,6,7,9,14,15,16,20,23,24]\n",
    "treshhold = 10\n",
    "segment_length = 46 * 10\n",
    "\n",
    "get_shallow_data(subjects, treshhold, segment_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827604b0-51b3-4cc3-9325-39811cb1f9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
