{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGG VGGFace\n",
    "This notebook contains the code for the IGG analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from PIL import Image\n",
    "import imutils\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.decomposition import PCA\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displayinh the number of GPUs available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a test image, resize it, and convert it to grayscale\n",
    "def load_image(path, show=False, gray_show=False):\n",
    "    test_image = cv2.imread(path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    test_image = imutils.resize(test_image, width=500)\n",
    "    gray = cv2.cvtColor(test_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(test_image)\n",
    "        plt.show()\n",
    "        if gray_show:\n",
    "            plt.imshow(gray, cmap='gray')\n",
    "            plt.show()\n",
    "    return test_image, gray\n",
    "\n",
    "def detect_faces(face_detector, gray, img, scale_factor, frame_num, show_multi_faces = False):\n",
    "    detections = haar_cascade.detectMultiScale(gray, scaleFactor=scale_factor, minNeighbors=5, minSize=(150, 150), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    #Checking if there are more than 1 detected faces\n",
    "    if len(detections) > 1:\n",
    "        print('Multiple faces detected', frame_num)\n",
    "        return False\n",
    "    elif len(detections) == 1:\n",
    "        face = detections[0]\n",
    "    # if no face detected\n",
    "    elif len(detections) == 0:\n",
    "        print('No face detected', frame_num)\n",
    "        return False\n",
    "    fX, fY, fW, fH = face[0], face[1], face[2], face[3]\n",
    "    face_img = Image.fromarray(img[fY:fY + fH, fX:fX + fW])\n",
    "    face_img = face_img.resize((224, 224))\n",
    "    #face_img.show()\n",
    "    return face_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_face(path, face_detector, model, scale_factor):\n",
    "    test_img, gray = load_image(path, show=False)\n",
    "    face = detect_faces(face_detector, gray, test_img, scale_factor, 1, show_multi_faces=False)\n",
    "\n",
    "    if not face:\n",
    "        return 0, False\n",
    "\n",
    "    face_array = np.asarray(face)\n",
    "    # pixels = face_array.astype('float32')\n",
    "    # samples = np.expand_dims(pixels, axis=0)\n",
    "    # samples = preprocess_input(samples, version=2)\n",
    "    # embedding = model.predict(samples, verbose=0)\n",
    "    # embeddings.append(embedding[0])\n",
    "    return tf.convert_to_tensor(face_array, dtype=tf.uint8), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# haar Cascade path\n",
    "cascade_path = '../models/haarcascade_frontalface_default.xml'\n",
    "# create haar cascade\n",
    "haar_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "face_detector = 'haar'\n",
    "\n",
    "frame_start = 80000\n",
    "frame_end = 80010\n",
    "frames = range(frame_start, frame_end + 1)\n",
    "\n",
    "scale_factor = 1.04\n",
    "\n",
    "folder_path = '../frames/P11404/sleepy/frame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   try:\n",
    "#     tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=100)])\n",
    "#   except RuntimeError as e:\n",
    "#     print(e)\n",
    "    \n",
    "print(\"GPU is set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 80000\n",
    "path = folder_path + str(frame) + '.jpg'\n",
    "face = get_face(path, face_detector, model, scale_factor)[0]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.imshow(face)\n",
    "ax.set_title(path[-14:-4])\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline =tf.zeros(shape=(224,224,3), dtype=tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_steps=50\n",
    "alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)\n",
    "\n",
    "def interpolate_images(baseline, image, alphas):\n",
    "    alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "    baseline_x = tf.expand_dims(baseline, axis=0)\n",
    "    input_x = tf.expand_dims(image, axis=0)\n",
    "    delta = input_x - baseline_x\n",
    "    delta = tf.cast(delta, tf.float32)\n",
    "    baseline_x = tf.cast(baseline_x, tf.float32)\n",
    "    images = baseline_x +  alphas_x * delta\n",
    "    return images\n",
    "\n",
    "gc.collect()\n",
    "interpolated_images = interpolate_images(baseline=baseline, image=face, alphas=alphas)\n",
    "interpolated_images_int = tf.cast(interpolated_images, tf.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "i = 0\n",
    "for alpha, image in zip(alphas[0::10], interpolated_images_int[0::10]):\n",
    "    i += 1\n",
    "    plt.subplot(1, len(alphas[0::10]), i)\n",
    "    plt.title(f'alpha: {alpha:.1f}')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_predictions(img, k=3):\n",
    "    image = tf.expand_dims(img, 0)\n",
    "    predictions = model(image)\n",
    "    probs = tf.nn.softmax(predictions, axis=-1)\n",
    "    top_probs, top_idxs = tf.math.top_k(input=probs, k=k)\n",
    "    top_labels = np.array(tuple(top_idxs[0]) )\n",
    "    return top_labels, top_probs[0]\n",
    "\n",
    "#Display the image with top 3 prediction from the model\n",
    "plt.imshow(face)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "pred_label, pred_prob = top_k_predictions(face)\n",
    "print(pred_label, pred_prob)\n",
    "target_class = pred_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradients(images, target_class_idx):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(images)\n",
    "        logits = model(images)\n",
    "        probs = tf.nn.softmax(logits, axis=-1)[:, target_class_idx]\n",
    "    return tape.gradient(probs, images)\n",
    "path_gradients = compute_gradients(images=interpolated_images, target_class_idx=target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def integral_approximation(gradients):\n",
    "    # riemann_trapezoidal\n",
    "    grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
    "    return integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def integrated_gradients(baseline, image, target_class_idx, m_steps=50, batch_size=1):\n",
    "    # 1. Generate alphas.\n",
    "    alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)\n",
    "    # Initialize TensorArray outside loop to collect gradients.    \n",
    "    gradient_batches = tf.TensorArray(tf.float32, size=m_steps+1)\n",
    "    \n",
    "    # Iterate alphas range and batch computation for speed, memory #efficiency, and scaling to larger m_steps.\n",
    "    for alpha in tf.range(0, len(alphas), batch_size):\n",
    "        from_ = alpha\n",
    "        to = tf.minimum(from_ + batch_size, len(alphas))\n",
    "        alpha_batch = alphas[from_:to]\n",
    "        \n",
    "    # 2. Generate interpolated inputs between baseline and input.\n",
    "    interpolated_path_input_batch = interpolate_images(baseline=baseline, image=image, alphas=alpha_batch)\n",
    "    # 3. Compute gradients between model outputs and interpolated inputs.\n",
    "    gradient_batch = compute_gradients(images=interpolated_path_input_batch, target_class_idx=target_class_idx)\n",
    "    \n",
    "    # Write batch indices and gradients to extend TensorArray.\n",
    "    gradient_batches = gradient_batches.scatter(tf.range(from_, to), gradient_batch)    \n",
    "  \n",
    "    # Stack path gradients together row-wise into single tensor.\n",
    "    total_gradients = gradient_batches.stack()\n",
    "    # 4. Integral approximation through averaging gradients.\n",
    "    avg_gradients = integral_approximation(gradients=total_gradients)\n",
    "    # 5. Scale integrated gradients with respect to input.\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    baseline = tf.cast(baseline, tf.float32)\n",
    "\n",
    "    integrated_gradients = (image - baseline) * avg_gradients\n",
    "    return integrated_gradients\n",
    "ig_attributions = integrated_gradients(baseline=baseline, image=face, target_class_idx=target_class, m_steps=283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_IG(baseline, image, target_class_idx, m_steps=50, cmap=None, overlay_alpha=0.4):\n",
    "    attributions = integrated_gradients(baseline=baseline, image=image, target_class_idx=target_class_idx, m_steps=m_steps)\n",
    "    #print(attributions)\n",
    "    #attributions = tf.cast(attributions, tf.int8)\n",
    "    attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize=   (8, 8))\n",
    "    axs[0, 0].set_title('Attribution mask')\n",
    "    axs[0, 0].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 1].set_title('Overlay IG on Input image ')\n",
    "    axs[0, 1].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[0, 1].imshow(image, alpha=overlay_alpha)\n",
    "    axs[0, 1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/igg_sub10_normal.jpg')\n",
    "    return fig\n",
    "_ = plot_img_IG(image=face, baseline=baseline, target_class_idx=target_class, m_steps=240, cmap=plt.cm.inferno, overlay_alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haar Cascade path\n",
    "cascade_path = '../models/haarcascade_frontalface_default.xml'\n",
    "# create haar cascade\n",
    "haar_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "face_detector = 'haar'\n",
    "\n",
    "frame_start = 120000\n",
    "frame_end = 130000\n",
    "frames = range(frame_start, frame_end + 1)\n",
    "\n",
    "scale_factor = 1.03\n",
    "\n",
    "folder_path = '../frames/P11404/sleepy/frame'\n",
    "\n",
    "baseline =tf.zeros(shape=(224,224,3), dtype=tf.uint8)\n",
    "\n",
    "def get_multiple_ig(frames, face_detector, model, scale_factor, folder_path, baseline):\n",
    "    ig_list = []\n",
    "    for frame in frames:\n",
    "        if frame % 1000 == 0:\n",
    "            print(frame)\n",
    "        path = folder_path + str(frame) + '.jpg'\n",
    "        face, boolean = get_face(path, face_detector, model, scale_factor)\n",
    "        if boolean == False:\n",
    "            continue\n",
    "        pred_label, pred_prob = top_k_predictions(face)\n",
    "        target_class = pred_label[0]\n",
    "        ig_attributions = integrated_gradients(baseline=baseline, image=face, target_class_idx=target_class, m_steps=283)\n",
    "        ig_list.append(ig_attributions)\n",
    "    return ig_list, face\n",
    "\n",
    "ig_values, face = get_multiple_ig(frames, face_detector, model, scale_factor, folder_path, baseline)\n",
    "print(len(ig_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_aggregated_ig(ig_values):\n",
    "    num = len(ig_values)\n",
    "    print(tf.shape(ig_values[0]))\n",
    "    sum_values = sum(ig_values)\n",
    "    agg_ig = sum_values / num\n",
    "    print(tf.shape(agg_ig))\n",
    "    return agg_ig\n",
    "    \n",
    "agg_ig = get_aggregated_ig(ig_values)\n",
    "print(len(ig_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = 120000\n",
    "path = folder_path + str(frame) + '.jpg'\n",
    "face = get_face(path, face_detector, model, scale_factor)[0]\n",
    "\n",
    "def plot_img_IG(face, agg_ig, cmap=None, overlay_alpha=0.4):\n",
    "    attribution_mask = tf.reduce_sum(tf.math.abs(agg_ig), axis=-1)\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize=   (8, 8))\n",
    "    axs[0, 0].set_title('Attribution mask')\n",
    "    axs[0, 0].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[0, 0].axis('off')\n",
    "    axs[0, 1].set_title('Overlay IG on facial image')\n",
    "    axs[0, 1].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[0, 1].imshow(face, alpha=overlay_alpha)\n",
    "    axs[0, 1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../final_figures/agg_ig_sub4_sleepy_30-40k.jpg')\n",
    "    return fig\n",
    "_ = plot_img_IG(face, agg_ig, cmap=plt.cm.inferno, overlay_alpha=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
